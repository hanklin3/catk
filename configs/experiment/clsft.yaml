# @package _global_

defaults:
  - override /trainer: ddp
  # - override /model: smart

model:
  model_config:
    lr: 5e-5
    lr_min_ratio: 0.05
    token_processor:
      map_token_sampling: # open-loop
        num_k: 1 # for k nearest neighbors
        temp: 1.0 # uniform sampling
      agent_token_sampling: # closed-loop
        num_k: 1 # for k nearest neighbors
        temp: 1.0
    training_rollout_sampling:
      criterium: topk_prob_sampled_with_dist # {topk_dist_sampled_with_prob, topk_prob, topk_prob_sampled_with_dist}
      num_k: 32 # for k nearest neighbors, set to -1 to turn-off closed-loop training
      temp: 1e-5 # catk = topk_prob_sampled_with_dist with temp=1e-5
    training_loss:
      use_gt_raw: true
      gt_thresh_scale_length: -1  # {"veh": 4.8, "cyc": 2.0, "ped": 1.0}
      label_smoothing: 0.0
      rollout_as_gt: false
    finetune: true

ckpt_path: logs/pre_bc-debug/runs/2024-12-19_10-04-48/checkpoints/last.ckpt

trainer:
  limit_train_batches: 1.0
  limit_val_batches: 0.1
  check_val_every_n_epoch: 16

data:
  train_batch_size: 6 #10
  val_batch_size: 4 #10
  test_batch_size: 4 #10
  num_workers: 16

action: finetune