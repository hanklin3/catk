# @package _global_

defaults:
  # - override /trainer: ddp
  - override /model: smart

model:
  model_config:
    lr: 5e-4
    lr_min_ratio: 1e-2
    token_processor:
      map_token_sampling: # open-loop
        num_k: 1 # for k nearest neighbors
        temp: 1.0 # uniform sampling
      agent_token_sampling: # closed-loop
        num_k: 1 # for k nearest neighbors
        temp: 1.0

# ckpt_path: logs/pre_bc-debug/runs/2024-12-18_19-17-33/checkpoints/epoch_009.ckpt #null
# ckpt_path: CKPT_FOR_RESUME.ckpt # to resume training

trainer:
  limit_train_batches: 1.0
  limit_val_batches: 0.1
  check_val_every_n_epoch: 1
  max_epochs: 64

data:
  train_batch_size: 2 #10
  val_batch_size: 4 #10
  test_batch_size: 4 #10
  num_workers: 10